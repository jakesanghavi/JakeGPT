{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "08084463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from my_tokenizer import RegexTokenizer\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e225b5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in our data file\n",
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8175b184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a list of every character in the text\n",
    "# char_list = sorted(list(set(text)))\n",
    "\n",
    "# # This converts individual characters to integers (encoder)\n",
    "# in_encode = {char: i for i, char in enumerate(char_list)}\n",
    "# # This converts individual integers to chatacters (decoder)\n",
    "# out_decode = {i: char for i, char in enumerate(char_list)}\n",
    "\n",
    "# # Define our encoder and decoder as function\n",
    "# encode = lambda string: [in_encode[char] for char in string]\n",
    "# decode = lambda encoding: ''.join([out_decode[integer] for integer in encoding])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a790d58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexTokenizer()\n",
    "path = os.path.join(\"models\", \"v1.model\")\n",
    "tokenizer.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "69e465f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Store our entire text as a tensor\n",
    "# data = torch.tensor(encode(text), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "01b706e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store our entire text as a tensor\n",
    "data = torch.tensor(tokenizer.encode(text, \"all\"), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b7353270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the text into train and test (video uses 0.9)\n",
    "train_data = data[:int(0.8*len(data))]\n",
    "val_data = data[int(0.8*len(data)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1cc7ec7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a block size to train the model. This is the maximum amount of tokens\n",
    "# being attended to at a time\n",
    "BLOCK_SIZE = 128\n",
    "# Set a batch size (number of random blocks we will select)\n",
    "BATCH_SIZE = 32\n",
    "# The size of our vocabulary will be the number of distinct characters\n",
    "# as we encode at the character level.\n",
    "# VOCAB_SIZE = len(char_list)\n",
    "VOCAB_SIZE = 512\n",
    "# The length of our embeddings\n",
    "N_EMBED=120\n",
    "# Use the GPU if it is available\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "else:\n",
    "    DEVICE = 'CPU'\n",
    "    print (\"MPS device not found.\")\n",
    "# Set our learning rate for Adam\n",
    "LR = 3e-4\n",
    "# Choose the number of heads for multi-headed attention (heads per block)\n",
    "N_HEAD=6\n",
    "# Set the number of times to repeat the block\n",
    "N_LAYER = 6\n",
    "# Choose a dropout percentage (prevent overfitting)\n",
    "DROPOUT = 0.2\n",
    "# Choose the number of times to iterate while training\n",
    "MAX_ITER = 5000\n",
    "# Set an interval at which to evaluate the loss of the network\n",
    "EVAL_ITER = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "365932cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - BLOCK_SIZE, (BATCH_SIZE,))\n",
    "    x = torch.stack([data[i:i+BLOCK_SIZE] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+BLOCK_SIZE+1] for i in ix])\n",
    "    x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7fafee16",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch, y_batch = get_batch('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6e1c7fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "'''Implements a single head of self-attention'''\n",
    "class Head(nn.Module):\n",
    "    \n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        # Set the key, query, and value vectors operations\n",
    "        # These will reduce the size of the vector to head_size\n",
    "        # Because we use multi-headed attention, we will have N heads, \n",
    "        # Where N * head_size = N_EMBED (embedding length)\n",
    "        self.key = nn.Linear(N_EMBED, head_size, bias=False)\n",
    "        self.query = nn.Linear(N_EMBED, head_size, bias=False)\n",
    "        self.value = nn.Linear(N_EMBED, head_size, bias=False)\n",
    "        # Create a lower triangular ones matrix to aid with softmax\n",
    "        self.register_buffer('lower_tri', torch.tril(torch.ones(BLOCK_SIZE, BLOCK_SIZE)))\n",
    "        # Add a dropout layer to prevent overfitting\n",
    "        self.dropout = nn.Dropout(DROPOUT)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # B = length of sequence (called \"seq\" in paper)number of batches being computed in parallel\n",
    "        # T = length of sequence (called \"seq\" in paper). This is equal to block size.\n",
    "        # C = embedding vector size (called d_model in paper)\n",
    "        B, T, C = x.shape\n",
    "        q = self.query(x) # Query: (B x T x C)\n",
    "        k = self.key(x) # Key: (B x T x C)\n",
    "        \n",
    "        # Take the dot product of queries and keys as a matrix to get similarities (attention!)\n",
    "        # Have to transpose the last two dimensions to make the shapes correct\n",
    "        # This will give us a single \"similarity score\" for each token pair\n",
    "        # C is the head size here. We have to add this division at the end to recover unit variance.\n",
    "        # Otherwise, softmax will create very deterministic rows\n",
    "        weights = q @ k.transpose(-2, -1) * C**(-0.5) # (B x T x C) @ (B x C x T) --> (B x T x T)\n",
    "        # Convert the upper triangular entries in the weight matrix to -infinity. This makes it so that the\n",
    "        # future tokens cannot communicate with the past ones. When making an encoder block, this line\n",
    "        # would be removed.\n",
    "        weights = weights.masked_fill(self.lower_tri[:T, :T] == 0, float('-inf')) # (B x T x T)\n",
    "        # Apply softmax to get amount of attention each token pays to each token\n",
    "        weights = F.softmax(weights, dim=-1)\n",
    "        weights = self.dropout(weights)\n",
    "        \n",
    "        v = self.value(x) # Value: (B x T x C)\n",
    "        \n",
    "        # Get the dot product of the weights and the value to get the final embeddings for the block\n",
    "        # This scales the value vector for each token by its entry in the weight matrix\n",
    "        out = weights @ v # (B x T x T) @ (B x T x C) --> (B x T x C)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b0e64d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_heads, head_size):\n",
    "        super().__init__()\n",
    "        # Create multiple heads\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(n_heads)])\n",
    "        self.proj = nn.Linear(N_EMBED, N_EMBED)\n",
    "        # Add a dropout layer to prevent overfitting\n",
    "        self.dropout = nn.Dropout(DROPOUT)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Concatenate the embeddings from each head\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        # Pass the concatenated embeddings through a projection layer\n",
    "        # to try to get their information to interact\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "06442ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_embed):\n",
    "        super().__init__()\n",
    "        # These 4x multipliers are based on the Attention is All You Need paper.\n",
    "        # This gives us a larger dimension in the middle of the network, potentially\n",
    "        # learning more relationships.\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embed, 4 * n_embed),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embed, n_embed),\n",
    "            nn.Dropout(DROPOUT)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Feed the input through the above network\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9cd72500",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_embed, n_head):\n",
    "        super().__init__()\n",
    "        # Initialize the head size (embedding size per head)\n",
    "        head_size = n_embed // n_head\n",
    "        # Initialize our multi-headed architecture\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        # Intialize our feed-forward structure\n",
    "        self.f_forward = FeedForward(n_embed)\n",
    "        # Layer norm gives rows unit Gaussian distributions at initialization\n",
    "        # After training this likely will not be the case, and the network will\n",
    "        # instead have a learned distribution.\n",
    "        self.layer_norm1 = nn.LayerNorm(n_embed)\n",
    "        self.layer_norm2 = nn.LayerNorm(n_embed)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Using x = x + ... implements residual connections\n",
    "        # Residual connections add stability and other benefits.\n",
    "        # We also add layer\n",
    "        x = x + self.sa(self.layer_norm1(x))\n",
    "        x = x + self.f_forward(self.layer_norm2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fc7d864b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniGPTDecoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # Make a token embedding table for each character\n",
    "        self.token_embedding_table = nn.Embedding(VOCAB_SIZE, N_EMBED)\n",
    "        # Make a positional embedding table to keep track of relative char position\n",
    "        self.position_embedding_table = nn.Embedding(BLOCK_SIZE, N_EMBED)\n",
    "        # Implement self attention via Multi-Headed Attention blocks\n",
    "        self.blocks = nn.Sequential(*[Block(N_EMBED, n_head=N_HEAD) for _ in range(N_LAYER)])\n",
    "        # Add layer norm\n",
    "        self.layer_norm = nn.LayerNorm(N_EMBED)\n",
    "        # Add a final linear layer to bring the dimensionality back to VOCAB_SIZE\n",
    "        self.lm_head = nn.Linear(N_EMBED, VOCAB_SIZE)\n",
    "        \n",
    "    def forward(self, ix, targets=None):\n",
    "        B, T = ix.shape\n",
    "        \n",
    "        # Gets a (B,T,C) embedding (Batch, Time, Channels)\n",
    "        # Use as logits (scores) for next character in sequence\n",
    "        token_embed = self.token_embedding_table(ix) # (B x T x C)\n",
    "        # Gets (T, C) position embedding\n",
    "        pos_embed = self.position_embedding_table(torch.arange(T, device=DEVICE)) # (T x C)\n",
    "        # Combine the two embeddings into one\n",
    "        embed = token_embed + pos_embed\n",
    "        # Pass the embedding through the attention block\n",
    "        embed = self.blocks(embed)\n",
    "        # Get the logits\n",
    "        logits = self.lm_head(embed) # (B x T x VOCAB_SIZE)\n",
    "        \n",
    "        # We don't want any loss when generating\n",
    "        if targets is None:\n",
    "            loss=None\n",
    "        \n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "\n",
    "            # Collapse B and T into one dimension to fit the cross_entropy usage\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "\n",
    "            # Check how well you predict the next char based on the logits\n",
    "            # The correct next token in the char's row should have a high value, and the rest should be low\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "    \n",
    "    # Generate the next tokens based on a given input\n",
    "    def generate(self, ix, max_new_tokens):\n",
    "        # ix = B x T array of indices in current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # Reduce the size to BLOCK_SIZE to not overflow the model\n",
    "            ix_cond = ix[:, -BLOCK_SIZE:]\n",
    "            # get the predictions at the current index\n",
    "            logits, loss = self(ix_cond)\n",
    "            # Look at just the last time step\n",
    "            logits = logits[:, -1, :] # Collapse logits to B x C\n",
    "            # Apply softmax to get probs\n",
    "            probs = F.softmax(logits, dim=-1) # B x C\n",
    "            # Sample from a distribution to introduce noise\n",
    "            # We don't want to always get the same generation\n",
    "            next_ix = torch.multinomial(probs, num_samples=1)\n",
    "            # Add the predicted character to our output\n",
    "            ix = torch.cat((ix, next_ix), dim=1)\n",
    "        return ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "bde32a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.183 million parameters\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = MiniGPTDecoder(len(char_list))\n",
    "# Move the model to the GPU if possible\n",
    "model = model.to(DEVICE)\n",
    "# logits, loss = model(x_batch, y_batch)\n",
    "print(f\"{round(sum(p.numel() for p in model.parameters())/1e6, 3)} million parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c604d5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the PyTorch Adam optimizer\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "dba24d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 100: 0.0 minutes in.\n",
      "Iteration 200: 0.0 minutes in.\n",
      "Iteration 300: 0.0 minutes in.\n",
      "Iteration 400: 1.0 minutes in.\n",
      "Iteration 500: 1.0 minutes in.\n",
      "Iteration 600: 1.0 minutes in.\n",
      "Iteration 700: 1.0 minutes in.\n",
      "Iteration 800: 2.0 minutes in.\n",
      "Iteration 900: 3.0 minutes in.\n",
      "Iteration 1000: 6.0 minutes in.\n",
      "Iteration 1100: 9.0 minutes in.\n",
      "Iteration 1200: 10.0 minutes in.\n",
      "Iteration 1300: 10.0 minutes in.\n",
      "Iteration 1400: 10.0 minutes in.\n",
      "Iteration 1500: 11.0 minutes in.\n",
      "Iteration 1600: 11.0 minutes in.\n",
      "Iteration 1700: 11.0 minutes in.\n",
      "Iteration 1800: 11.0 minutes in.\n",
      "Iteration 1900: 12.0 minutes in.\n",
      "Iteration 2000: 12.0 minutes in.\n",
      "Iteration 2100: 12.0 minutes in.\n",
      "Iteration 2200: 12.0 minutes in.\n",
      "Iteration 2300: 13.0 minutes in.\n",
      "Iteration 2400: 13.0 minutes in.\n",
      "Iteration 2500: 34.0 minutes in.\n",
      "Iteration 2600: 43.0 minutes in.\n",
      "Iteration 2700: 43.0 minutes in.\n",
      "Iteration 2800: 43.0 minutes in.\n",
      "Iteration 2900: 44.0 minutes in.\n",
      "Iteration 3000: 44.0 minutes in.\n",
      "Iteration 3100: 44.0 minutes in.\n",
      "Iteration 3200: 44.0 minutes in.\n",
      "Iteration 3300: 45.0 minutes in.\n",
      "Iteration 3400: 45.0 minutes in.\n",
      "Iteration 3500: 45.0 minutes in.\n",
      "Iteration 3600: 50.0 minutes in.\n",
      "Iteration 3700: 50.0 minutes in.\n",
      "Iteration 3800: 50.0 minutes in.\n",
      "Iteration 3900: 50.0 minutes in.\n",
      "Iteration 4000: 51.0 minutes in.\n",
      "Iteration 4100: 51.0 minutes in.\n",
      "Iteration 4200: 51.0 minutes in.\n",
      "Iteration 4300: 51.0 minutes in.\n",
      "Iteration 4400: 52.0 minutes in.\n",
      "Iteration 4500: 52.0 minutes in.\n",
      "Iteration 4600: 52.0 minutes in.\n",
      "Iteration 4700: 52.0 minutes in.\n",
      "Iteration 4800: 53.0 minutes in.\n",
      "Iteration 4900: 53.0 minutes in.\n",
      "Iteration 5000: 53.0 minutes in.\n",
      "Training time: 0.0 hours, 53.0 minutes, and 43.639 seconds.\n"
     ]
    }
   ],
   "source": [
    "loss_prog = []\n",
    "import time\n",
    "\n",
    "t1 = time.time()\n",
    "for iter_num in range(1, MAX_ITER+1):\n",
    "    \n",
    "    # Check on the progress every EVAL_ITER iterations.\n",
    "    if iter_num % EVAL_ITER == 0:\n",
    "        print(f\"Iteration {iter_num}: {(time.time() - t1)//60} minutes in.\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    \n",
    "    # every once in a while append the loss to the loss tracker\n",
    "    if iter_num % EVAL_ITER == 0 or iter_num == MAX_ITER:\n",
    "        loss_prog.append(round(loss.item(), 3))\n",
    "    \n",
    "    # This command changes gradient zeros to None. Tends to increase speed\n",
    "    opt.zero_grad(set_to_none=True)\n",
    "    # Backpropagate\n",
    "    loss.backward()\n",
    "    # Step the optimizer forward\n",
    "    opt.step()\n",
    "    \n",
    "print(f\"Training time: {(time.time() - t1) // 3600} hours, {((time.time() - t1)//60)%60} minutes, and {round((time.time() - t1)%60, 3)} seconds.\")\n",
    "\n",
    "# Create a zero to begin the generation\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=DEVICE)\n",
    "# Generate some tokens\n",
    "# generated = decode(model.generate(context, max_new_tokens=500)[0].tolist())\n",
    "generated = tokenizer.decode(model.generate(context, max_new_tokens=500)[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3dc10494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.plot(np.arange(1, len(loss_prog)+1, 1), loss_prog)\n",
    "plt.xlabel('Iteration (hundreds)')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d8ba0cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0000USy.\n",
      "\n",
      "LUCIO:\n",
      "All most be? what hone?\n",
      "I will we could this is saymain\n",
      "Thou which done my life in ads of Lord of our deeems,\n",
      "This fond, in his acque his city,\n",
      "But evinously of thine a son and ans\n",
      "asid a trie as not me, too triive femper\n",
      "My ext not intell: look, that, all it as a\n",
      "peies, dove you he us not true.\n",
      "\n",
      "LUCIO:\n",
      "Most mine memes them king?\n",
      "\n",
      "First Lord:\n",
      "The pagours shall; therebroth meance of thy saficers,\n",
      "Who handed, we'll be or by king out of Caster. So\n",
      "y Larewear me. Nursem: let meet him, forth in\n",
      "Are well use that from this asleday.\n",
      "\n",
      "P shallapege:\n",
      "How, fear thou hear a thants he like you did;\n",
      "orn very enters; from the hoody courtues.\n",
      "\n",
      "HUn:\n",
      "What is it so, you?\n",
      "\n",
      "CORIOLANUS:\n",
      "What is grave to--the den wowerous as on, and I in mays, hath to\n",
      "Than o'therdving worrow me foughther sauck.\n",
      "\n",
      "CAMENESBY:\n",
      "Evens field, the mighty, what never\n",
      "neives, town'd name to his brother.\n",
      "\n",
      "ANGARET:\n",
      "Thank off sister to he e of the fhat\n",
      "I whose cinterss where we pardon as none.\n",
      "\n",
      "GLOUCESTER:\n",
      "His name for forbernate murth:\n",
      "If din the bring thy head.\n",
      "\n",
      "WISASTA:\n",
      "Yes we it bec\n"
     ]
    }
   ],
   "source": [
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2814ce29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "token_embedding_table.weight \t torch.Size([512, 120])\n",
      "position_embedding_table.weight \t torch.Size([128, 120])\n",
      "blocks.0.sa.heads.0.lower_tri \t torch.Size([128, 128])\n",
      "blocks.0.sa.heads.0.key.weight \t torch.Size([20, 120])\n",
      "blocks.0.sa.heads.0.query.weight \t torch.Size([20, 120])\n",
      "blocks.0.sa.heads.0.value.weight \t torch.Size([20, 120])\n",
      "blocks.0.sa.heads.1.lower_tri \t torch.Size([128, 128])\n",
      "blocks.0.sa.heads.1.key.weight \t torch.Size([20, 120])\n",
      "blocks.0.sa.heads.1.query.weight \t torch.Size([20, 120])\n",
      "blocks.0.sa.heads.1.value.weight \t torch.Size([20, 120])\n",
      "blocks.0.sa.heads.2.lower_tri \t torch.Size([128, 128])\n",
      "blocks.0.sa.heads.2.key.weight \t torch.Size([20, 120])\n",
      "blocks.0.sa.heads.2.query.weight \t torch.Size([20, 120])\n",
      "blocks.0.sa.heads.2.value.weight \t torch.Size([20, 120])\n",
      "blocks.0.sa.heads.3.lower_tri \t torch.Size([128, 128])\n",
      "blocks.0.sa.heads.3.key.weight \t torch.Size([20, 120])\n",
      "blocks.0.sa.heads.3.query.weight \t torch.Size([20, 120])\n",
      "blocks.0.sa.heads.3.value.weight \t torch.Size([20, 120])\n",
      "blocks.0.sa.heads.4.lower_tri \t torch.Size([128, 128])\n",
      "blocks.0.sa.heads.4.key.weight \t torch.Size([20, 120])\n",
      "blocks.0.sa.heads.4.query.weight \t torch.Size([20, 120])\n",
      "blocks.0.sa.heads.4.value.weight \t torch.Size([20, 120])\n",
      "blocks.0.sa.heads.5.lower_tri \t torch.Size([128, 128])\n",
      "blocks.0.sa.heads.5.key.weight \t torch.Size([20, 120])\n",
      "blocks.0.sa.heads.5.query.weight \t torch.Size([20, 120])\n",
      "blocks.0.sa.heads.5.value.weight \t torch.Size([20, 120])\n",
      "blocks.0.sa.proj.weight \t torch.Size([120, 120])\n",
      "blocks.0.sa.proj.bias \t torch.Size([120])\n",
      "blocks.0.f_forward.net.0.weight \t torch.Size([480, 120])\n",
      "blocks.0.f_forward.net.0.bias \t torch.Size([480])\n",
      "blocks.0.f_forward.net.2.weight \t torch.Size([120, 480])\n",
      "blocks.0.f_forward.net.2.bias \t torch.Size([120])\n",
      "blocks.0.layer_norm1.weight \t torch.Size([120])\n",
      "blocks.0.layer_norm1.bias \t torch.Size([120])\n",
      "blocks.0.layer_norm2.weight \t torch.Size([120])\n",
      "blocks.0.layer_norm2.bias \t torch.Size([120])\n",
      "blocks.1.sa.heads.0.lower_tri \t torch.Size([128, 128])\n",
      "blocks.1.sa.heads.0.key.weight \t torch.Size([20, 120])\n",
      "blocks.1.sa.heads.0.query.weight \t torch.Size([20, 120])\n",
      "blocks.1.sa.heads.0.value.weight \t torch.Size([20, 120])\n",
      "blocks.1.sa.heads.1.lower_tri \t torch.Size([128, 128])\n",
      "blocks.1.sa.heads.1.key.weight \t torch.Size([20, 120])\n",
      "blocks.1.sa.heads.1.query.weight \t torch.Size([20, 120])\n",
      "blocks.1.sa.heads.1.value.weight \t torch.Size([20, 120])\n",
      "blocks.1.sa.heads.2.lower_tri \t torch.Size([128, 128])\n",
      "blocks.1.sa.heads.2.key.weight \t torch.Size([20, 120])\n",
      "blocks.1.sa.heads.2.query.weight \t torch.Size([20, 120])\n",
      "blocks.1.sa.heads.2.value.weight \t torch.Size([20, 120])\n",
      "blocks.1.sa.heads.3.lower_tri \t torch.Size([128, 128])\n",
      "blocks.1.sa.heads.3.key.weight \t torch.Size([20, 120])\n",
      "blocks.1.sa.heads.3.query.weight \t torch.Size([20, 120])\n",
      "blocks.1.sa.heads.3.value.weight \t torch.Size([20, 120])\n",
      "blocks.1.sa.heads.4.lower_tri \t torch.Size([128, 128])\n",
      "blocks.1.sa.heads.4.key.weight \t torch.Size([20, 120])\n",
      "blocks.1.sa.heads.4.query.weight \t torch.Size([20, 120])\n",
      "blocks.1.sa.heads.4.value.weight \t torch.Size([20, 120])\n",
      "blocks.1.sa.heads.5.lower_tri \t torch.Size([128, 128])\n",
      "blocks.1.sa.heads.5.key.weight \t torch.Size([20, 120])\n",
      "blocks.1.sa.heads.5.query.weight \t torch.Size([20, 120])\n",
      "blocks.1.sa.heads.5.value.weight \t torch.Size([20, 120])\n",
      "blocks.1.sa.proj.weight \t torch.Size([120, 120])\n",
      "blocks.1.sa.proj.bias \t torch.Size([120])\n",
      "blocks.1.f_forward.net.0.weight \t torch.Size([480, 120])\n",
      "blocks.1.f_forward.net.0.bias \t torch.Size([480])\n",
      "blocks.1.f_forward.net.2.weight \t torch.Size([120, 480])\n",
      "blocks.1.f_forward.net.2.bias \t torch.Size([120])\n",
      "blocks.1.layer_norm1.weight \t torch.Size([120])\n",
      "blocks.1.layer_norm1.bias \t torch.Size([120])\n",
      "blocks.1.layer_norm2.weight \t torch.Size([120])\n",
      "blocks.1.layer_norm2.bias \t torch.Size([120])\n",
      "blocks.2.sa.heads.0.lower_tri \t torch.Size([128, 128])\n",
      "blocks.2.sa.heads.0.key.weight \t torch.Size([20, 120])\n",
      "blocks.2.sa.heads.0.query.weight \t torch.Size([20, 120])\n",
      "blocks.2.sa.heads.0.value.weight \t torch.Size([20, 120])\n",
      "blocks.2.sa.heads.1.lower_tri \t torch.Size([128, 128])\n",
      "blocks.2.sa.heads.1.key.weight \t torch.Size([20, 120])\n",
      "blocks.2.sa.heads.1.query.weight \t torch.Size([20, 120])\n",
      "blocks.2.sa.heads.1.value.weight \t torch.Size([20, 120])\n",
      "blocks.2.sa.heads.2.lower_tri \t torch.Size([128, 128])\n",
      "blocks.2.sa.heads.2.key.weight \t torch.Size([20, 120])\n",
      "blocks.2.sa.heads.2.query.weight \t torch.Size([20, 120])\n",
      "blocks.2.sa.heads.2.value.weight \t torch.Size([20, 120])\n",
      "blocks.2.sa.heads.3.lower_tri \t torch.Size([128, 128])\n",
      "blocks.2.sa.heads.3.key.weight \t torch.Size([20, 120])\n",
      "blocks.2.sa.heads.3.query.weight \t torch.Size([20, 120])\n",
      "blocks.2.sa.heads.3.value.weight \t torch.Size([20, 120])\n",
      "blocks.2.sa.heads.4.lower_tri \t torch.Size([128, 128])\n",
      "blocks.2.sa.heads.4.key.weight \t torch.Size([20, 120])\n",
      "blocks.2.sa.heads.4.query.weight \t torch.Size([20, 120])\n",
      "blocks.2.sa.heads.4.value.weight \t torch.Size([20, 120])\n",
      "blocks.2.sa.heads.5.lower_tri \t torch.Size([128, 128])\n",
      "blocks.2.sa.heads.5.key.weight \t torch.Size([20, 120])\n",
      "blocks.2.sa.heads.5.query.weight \t torch.Size([20, 120])\n",
      "blocks.2.sa.heads.5.value.weight \t torch.Size([20, 120])\n",
      "blocks.2.sa.proj.weight \t torch.Size([120, 120])\n",
      "blocks.2.sa.proj.bias \t torch.Size([120])\n",
      "blocks.2.f_forward.net.0.weight \t torch.Size([480, 120])\n",
      "blocks.2.f_forward.net.0.bias \t torch.Size([480])\n",
      "blocks.2.f_forward.net.2.weight \t torch.Size([120, 480])\n",
      "blocks.2.f_forward.net.2.bias \t torch.Size([120])\n",
      "blocks.2.layer_norm1.weight \t torch.Size([120])\n",
      "blocks.2.layer_norm1.bias \t torch.Size([120])\n",
      "blocks.2.layer_norm2.weight \t torch.Size([120])\n",
      "blocks.2.layer_norm2.bias \t torch.Size([120])\n",
      "blocks.3.sa.heads.0.lower_tri \t torch.Size([128, 128])\n",
      "blocks.3.sa.heads.0.key.weight \t torch.Size([20, 120])\n",
      "blocks.3.sa.heads.0.query.weight \t torch.Size([20, 120])\n",
      "blocks.3.sa.heads.0.value.weight \t torch.Size([20, 120])\n",
      "blocks.3.sa.heads.1.lower_tri \t torch.Size([128, 128])\n",
      "blocks.3.sa.heads.1.key.weight \t torch.Size([20, 120])\n",
      "blocks.3.sa.heads.1.query.weight \t torch.Size([20, 120])\n",
      "blocks.3.sa.heads.1.value.weight \t torch.Size([20, 120])\n",
      "blocks.3.sa.heads.2.lower_tri \t torch.Size([128, 128])\n",
      "blocks.3.sa.heads.2.key.weight \t torch.Size([20, 120])\n",
      "blocks.3.sa.heads.2.query.weight \t torch.Size([20, 120])\n",
      "blocks.3.sa.heads.2.value.weight \t torch.Size([20, 120])\n",
      "blocks.3.sa.heads.3.lower_tri \t torch.Size([128, 128])\n",
      "blocks.3.sa.heads.3.key.weight \t torch.Size([20, 120])\n",
      "blocks.3.sa.heads.3.query.weight \t torch.Size([20, 120])\n",
      "blocks.3.sa.heads.3.value.weight \t torch.Size([20, 120])\n",
      "blocks.3.sa.heads.4.lower_tri \t torch.Size([128, 128])\n",
      "blocks.3.sa.heads.4.key.weight \t torch.Size([20, 120])\n",
      "blocks.3.sa.heads.4.query.weight \t torch.Size([20, 120])\n",
      "blocks.3.sa.heads.4.value.weight \t torch.Size([20, 120])\n",
      "blocks.3.sa.heads.5.lower_tri \t torch.Size([128, 128])\n",
      "blocks.3.sa.heads.5.key.weight \t torch.Size([20, 120])\n",
      "blocks.3.sa.heads.5.query.weight \t torch.Size([20, 120])\n",
      "blocks.3.sa.heads.5.value.weight \t torch.Size([20, 120])\n",
      "blocks.3.sa.proj.weight \t torch.Size([120, 120])\n",
      "blocks.3.sa.proj.bias \t torch.Size([120])\n",
      "blocks.3.f_forward.net.0.weight \t torch.Size([480, 120])\n",
      "blocks.3.f_forward.net.0.bias \t torch.Size([480])\n",
      "blocks.3.f_forward.net.2.weight \t torch.Size([120, 480])\n",
      "blocks.3.f_forward.net.2.bias \t torch.Size([120])\n",
      "blocks.3.layer_norm1.weight \t torch.Size([120])\n",
      "blocks.3.layer_norm1.bias \t torch.Size([120])\n",
      "blocks.3.layer_norm2.weight \t torch.Size([120])\n",
      "blocks.3.layer_norm2.bias \t torch.Size([120])\n",
      "blocks.4.sa.heads.0.lower_tri \t torch.Size([128, 128])\n",
      "blocks.4.sa.heads.0.key.weight \t torch.Size([20, 120])\n",
      "blocks.4.sa.heads.0.query.weight \t torch.Size([20, 120])\n",
      "blocks.4.sa.heads.0.value.weight \t torch.Size([20, 120])\n",
      "blocks.4.sa.heads.1.lower_tri \t torch.Size([128, 128])\n",
      "blocks.4.sa.heads.1.key.weight \t torch.Size([20, 120])\n",
      "blocks.4.sa.heads.1.query.weight \t torch.Size([20, 120])\n",
      "blocks.4.sa.heads.1.value.weight \t torch.Size([20, 120])\n",
      "blocks.4.sa.heads.2.lower_tri \t torch.Size([128, 128])\n",
      "blocks.4.sa.heads.2.key.weight \t torch.Size([20, 120])\n",
      "blocks.4.sa.heads.2.query.weight \t torch.Size([20, 120])\n",
      "blocks.4.sa.heads.2.value.weight \t torch.Size([20, 120])\n",
      "blocks.4.sa.heads.3.lower_tri \t torch.Size([128, 128])\n",
      "blocks.4.sa.heads.3.key.weight \t torch.Size([20, 120])\n",
      "blocks.4.sa.heads.3.query.weight \t torch.Size([20, 120])\n",
      "blocks.4.sa.heads.3.value.weight \t torch.Size([20, 120])\n",
      "blocks.4.sa.heads.4.lower_tri \t torch.Size([128, 128])\n",
      "blocks.4.sa.heads.4.key.weight \t torch.Size([20, 120])\n",
      "blocks.4.sa.heads.4.query.weight \t torch.Size([20, 120])\n",
      "blocks.4.sa.heads.4.value.weight \t torch.Size([20, 120])\n",
      "blocks.4.sa.heads.5.lower_tri \t torch.Size([128, 128])\n",
      "blocks.4.sa.heads.5.key.weight \t torch.Size([20, 120])\n",
      "blocks.4.sa.heads.5.query.weight \t torch.Size([20, 120])\n",
      "blocks.4.sa.heads.5.value.weight \t torch.Size([20, 120])\n",
      "blocks.4.sa.proj.weight \t torch.Size([120, 120])\n",
      "blocks.4.sa.proj.bias \t torch.Size([120])\n",
      "blocks.4.f_forward.net.0.weight \t torch.Size([480, 120])\n",
      "blocks.4.f_forward.net.0.bias \t torch.Size([480])\n",
      "blocks.4.f_forward.net.2.weight \t torch.Size([120, 480])\n",
      "blocks.4.f_forward.net.2.bias \t torch.Size([120])\n",
      "blocks.4.layer_norm1.weight \t torch.Size([120])\n",
      "blocks.4.layer_norm1.bias \t torch.Size([120])\n",
      "blocks.4.layer_norm2.weight \t torch.Size([120])\n",
      "blocks.4.layer_norm2.bias \t torch.Size([120])\n",
      "blocks.5.sa.heads.0.lower_tri \t torch.Size([128, 128])\n",
      "blocks.5.sa.heads.0.key.weight \t torch.Size([20, 120])\n",
      "blocks.5.sa.heads.0.query.weight \t torch.Size([20, 120])\n",
      "blocks.5.sa.heads.0.value.weight \t torch.Size([20, 120])\n",
      "blocks.5.sa.heads.1.lower_tri \t torch.Size([128, 128])\n",
      "blocks.5.sa.heads.1.key.weight \t torch.Size([20, 120])\n",
      "blocks.5.sa.heads.1.query.weight \t torch.Size([20, 120])\n",
      "blocks.5.sa.heads.1.value.weight \t torch.Size([20, 120])\n",
      "blocks.5.sa.heads.2.lower_tri \t torch.Size([128, 128])\n",
      "blocks.5.sa.heads.2.key.weight \t torch.Size([20, 120])\n",
      "blocks.5.sa.heads.2.query.weight \t torch.Size([20, 120])\n",
      "blocks.5.sa.heads.2.value.weight \t torch.Size([20, 120])\n",
      "blocks.5.sa.heads.3.lower_tri \t torch.Size([128, 128])\n",
      "blocks.5.sa.heads.3.key.weight \t torch.Size([20, 120])\n",
      "blocks.5.sa.heads.3.query.weight \t torch.Size([20, 120])\n",
      "blocks.5.sa.heads.3.value.weight \t torch.Size([20, 120])\n",
      "blocks.5.sa.heads.4.lower_tri \t torch.Size([128, 128])\n",
      "blocks.5.sa.heads.4.key.weight \t torch.Size([20, 120])\n",
      "blocks.5.sa.heads.4.query.weight \t torch.Size([20, 120])\n",
      "blocks.5.sa.heads.4.value.weight \t torch.Size([20, 120])\n",
      "blocks.5.sa.heads.5.lower_tri \t torch.Size([128, 128])\n",
      "blocks.5.sa.heads.5.key.weight \t torch.Size([20, 120])\n",
      "blocks.5.sa.heads.5.query.weight \t torch.Size([20, 120])\n",
      "blocks.5.sa.heads.5.value.weight \t torch.Size([20, 120])\n",
      "blocks.5.sa.proj.weight \t torch.Size([120, 120])\n",
      "blocks.5.sa.proj.bias \t torch.Size([120])\n",
      "blocks.5.f_forward.net.0.weight \t torch.Size([480, 120])\n",
      "blocks.5.f_forward.net.0.bias \t torch.Size([480])\n",
      "blocks.5.f_forward.net.2.weight \t torch.Size([120, 480])\n",
      "blocks.5.f_forward.net.2.bias \t torch.Size([120])\n",
      "blocks.5.layer_norm1.weight \t torch.Size([120])\n",
      "blocks.5.layer_norm1.bias \t torch.Size([120])\n",
      "blocks.5.layer_norm2.weight \t torch.Size([120])\n",
      "blocks.5.layer_norm2.bias \t torch.Size([120])\n",
      "layer_norm.weight \t torch.Size([120])\n",
      "layer_norm.bias \t torch.Size([120])\n",
      "lm_head.weight \t torch.Size([512, 120])\n",
      "lm_head.bias \t torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "    \n",
    "torch.save(model.state_dict(), f\"shakespeare_{N_EMBED}_embed.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2121abb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(decode(model.generate(context, max_new_tokens=2000)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cff8ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
